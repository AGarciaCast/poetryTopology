{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q selenium\n",
    "#pip install ripser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import codecs\n",
    "import os\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementNotInteractableException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "import time, random\n",
    "\n",
    "\n",
    "import stablerank.srank as sr\n",
    "from ripser import ripser\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "import scipy.spatial as spatial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"./Data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_poem(driver):\n",
    "    elem = driver.find_element(By.CLASS_NAME, \"card-body\")\n",
    "    return \"\\n\\n\".join(p.text for p in elem.find_elements(By.CSS_SELECTOR, \"p\"))\n",
    "\n",
    "def iterate_poems(driver, df=None):\n",
    "\n",
    "    def get_elements():\n",
    "        mytable = driver.find_element(By.CSS_SELECTOR, 'tbody')\n",
    "        return mytable.find_elements(By.TAG_NAME, \"a\")\n",
    "\n",
    "    poems = []\n",
    "    titles = []\n",
    "    auth_elem = driver.find_element(By.CLASS_NAME, \"poet__name\")\n",
    "    author = auth_elem.text\n",
    "    main_window = driver.current_window_handle\n",
    "\n",
    "    i = 0\n",
    "    elements = get_elements()\n",
    "    for link in elements:\n",
    "        title = link.text\n",
    "        if df is not None and title in df[\"Title\"].values:\n",
    "            continue\n",
    "        \n",
    "        titles.append(title)\n",
    "\n",
    "        # Open link in new tab\n",
    "        link.send_keys(Keys.CONTROL + Keys.RETURN)\n",
    "        windows = driver.window_handles\n",
    "        driver.switch_to.window(windows[-1])\n",
    "\n",
    "        # Extract poem\n",
    "        time.sleep(2)\n",
    "        poems.append(extract_poem(driver))\n",
    "        time.sleep(5)\n",
    "\n",
    "        # Close Current Tab\n",
    "        driver.close()\n",
    "\n",
    "        # Put focus back on main window\n",
    "        driver.switch_to.window(main_window)\n",
    "        time.sleep(2)\n",
    "    \n",
    "    ActionChains(driver).move_to_element(auth_elem).perform()\n",
    "\n",
    "    return author, titles, poems\n",
    "\n",
    "def iterate_web(driver, web, df=None, max_p=5):\n",
    "    driver.get(web)\n",
    "    time.sleep(1)\n",
    "\n",
    "    more_next = True\n",
    "    if df is None:\n",
    "        df = pd.DataFrame({\"Poet\":[], \"Poem\":[], \"Title\":[]})\n",
    "        \n",
    "    i=0\n",
    "    while more_next and i < max_p:\n",
    "        # Obtain all poems author\n",
    "        author, titles, poems = iterate_poems(driver, df)\n",
    "\n",
    "        df_aux = pd.DataFrame({\"Poet\":[author]*len(poems),\n",
    "                                \"Poem\":poems,\n",
    "                                \"Title\":titles})\n",
    "\n",
    "        df = pd.concat([df, df_aux], ignore_index=True)\n",
    "        del df_aux\n",
    "\n",
    "        try:\n",
    "            time.sleep(5)\n",
    "            # Remove spam covering next\n",
    "            link = driver.find_element(By.XPATH,\n",
    "                                        '/html/body/w-div/span')\n",
    "            link.click()\n",
    "            time.sleep(0.5)\n",
    "        except (NoSuchElementException, ElementNotInteractableException):\n",
    "            pass\n",
    "\n",
    "        try:     \n",
    "            # Click next   \n",
    "            link = driver.find_element(By.CSS_SELECTOR,\n",
    "                                        '[aria-label=\"Go to next page\"]')\n",
    "            link.click()\n",
    "        except (NoSuchElementException, ElementNotInteractableException):\n",
    "            more_next = False\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    return df\n",
    "\n",
    "def extract_webs(webs, df=None):\n",
    "    driver = webdriver.Chrome()\n",
    "    if df is None:\n",
    "        df = pd.DataFrame({\"Poet\":[], \"Poem\":[], \"Title\":[]})\n",
    "        \n",
    "    for web in webs:\n",
    "        df = iterate_web(driver, web, df)\n",
    "        df.to_csv(os.path.join(path_data, \"PoetryData.csv\"),index=False)\n",
    "    \n",
    "    #time.sleep(50)\n",
    "    driver.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://poets.org/poet/e-e-cummings']\n"
     ]
    }
   ],
   "source": [
    "webs=[]\n",
    "with open(os.path.join(path_data, \"poets.txt\"), \"r\") as f:\n",
    "        webs = [w for w in f.readlines()]\n",
    "\n",
    "print(webs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(path_data, \"PoetryData.csv\"))\n",
    "df = extract_webs(webs, df)\n",
    "# df = extract_webs(webs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(path_data, \"PoetryData.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stylistic features classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Title', 'Poem', 'Poet'], dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(path_data, \"PoetryData.csv\"))\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Poet\n",
       "Langston Hughes        30\n",
       "Robert Frost           30\n",
       "Walt Whitman           30\n",
       "William Shakespeare    30\n",
       "W. B. Yeats            28\n",
       "Naomi Shihab Nye       26\n",
       "Emily Dickinson        22\n",
       "Christina Rossetti     20\n",
       "John Keats             19\n",
       "E. E. Cummings         15\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['Poet'])['Title'].count().nlargest(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "\n",
    "df = df.drop_duplicates(subset=['Title'], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Poet\n",
       "Langston Hughes        30\n",
       "Robert Frost           30\n",
       "Walt Whitman           30\n",
       "William Shakespeare    30\n",
       "W. B. Yeats            28\n",
       "Naomi Shihab Nye       26\n",
       "Emily Dickinson        22\n",
       "Christina Rossetti     20\n",
       "John Keats             19\n",
       "E. E. Cummings         15\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['Poet'])['Title'].count().nlargest(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby(['Poet']).head(30).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(path_data, \"PoetryData.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning\n",
    "df.loc[:, \"Poem\"] = df.loc[:, \"Poem\"].str.replace(\"\\r\",\"\")\n",
    "df.loc[:, \"Poem\"] = df.loc[:, \"Poem\"].str.rstrip(\"\\n\")\n",
    "\n",
    "df.loc[:, \"Title\"] = df.loc[:, \"Title\"].str.replace(r\" {2,}\", \"\", regex=True)\n",
    "df.loc[:, \"Title\"] = df.loc[:, \"Title\"].str.replace(\"\\n\", \"\")\n",
    "df.loc[:, \"Title\"] = df.loc[:, \"Title\"].str.replace(\"\\r\", \"\")\n",
    "\n",
    "df.loc[:, \"Poet\"] = df.loc[:, \"Poet\"].str.replace(\"\\n\", \"\")\n",
    "df.loc[:, \"Poet\"] = df.loc[:, \"Poet\"].str.replace(\"\\r\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num NaN Poems: 0\n",
      "Num NaN Poets: 0\n",
      "Num NaN Title: 0\n"
     ]
    }
   ],
   "source": [
    "nan_poems = df[\"Poem\"].isnull().sum()\n",
    "nan_poets = df[\"Poet\"].isnull().sum()\n",
    "nan_title = df[\"Title\"].isnull().sum()\n",
    "print(f\"Num NaN Poems: {nan_poems}\" +\n",
    "      f\"\\nNum NaN Poets: {nan_poets}\" +\n",
    "      f\"\\nNum NaN Title: {nan_title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Poem text files should be formatted as:\n",
    "TITLE\n",
    "AUTHOR\n",
    "TEXTTEXTTEXT[...]\n",
    "******\n",
    "TITLE2\n",
    "AUTHOR(2)\n",
    "TEXT...\n",
    "\"\"\"\n",
    "\n",
    "with codecs.open(os.path.join(path_data, \"style_input.txt\"), \"w\", \"utf-8\") as f:\n",
    "    aux = \"\"\n",
    "    for _, row in df.iterrows():\n",
    "        new_line = str(row[\"Title\"]) + \"\\n\" + str(row[\"Poet\"]) + \"\\n\" + str(row[\"Poem\"]) + \"\\n******\\n\"\n",
    "        \n",
    "        f.write(new_line)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of the points clouds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = sr.Distance(spatial.distance.pdist(data, \"euclidean\"))\n",
    "wisconsin_distances = distance.square_form()\n",
    "i = 0\n",
    "while i < len(wisconsin_distances):\n",
    "    plt.hist(wisconsin_distances[i])\n",
    "    i += 1\n",
    "\n",
    "distributions = {}\n",
    "distributions[\"0_15\"] = sr.get_distribution(name=\"uniform\", interval=[0,15])\n",
    "distributions[\"5_20\"] = sr.get_distribution(name=\"uniform\", interval=[5,20])\n",
    "distributions[\"10_25\"] = sr.get_distribution(name=\"uniform\", interval=[10,25])\n",
    "distributions[\"10_30\"] = sr.get_distribution(name=\"uniform\", interval=[10,30])\n",
    "distributions[\"15_30\"] = sr.get_distribution(name=\"uniform\", interval=[15,30])\n",
    "\n",
    "probabilities = {}\n",
    "for k in distributions.keys():\n",
    "    probabilities[k] = distributions[k](wisconsin_distances)\n",
    "\n",
    "number_instances=300\n",
    "sample_size=30\n",
    "\n",
    "start = timer()    \n",
    "h0_sr = {}\n",
    "h1_sr = {}\n",
    "for k in  distributions.keys():\n",
    "    h0_sr[k] = []\n",
    "    h1_sr[k] = []\n",
    "    for patient in wisconsin_distances:\n",
    "        p = distributions[k](patient)\n",
    "        s = sr.get_sample(number_instances, sample_size, p)\n",
    "        f = distance.get_h0sr(sample=s,clustering_method=\"complete\")\n",
    "        b = distance.get_bc(sample=s, maxdim=1)\n",
    "        g = sr.bc_to_sr(b,degree=\"H1\")\n",
    "        h0_sr[k].append(f)\n",
    "        h1_sr[k].append(g)\n",
    "end = timer()\n",
    "print(timedelta(seconds=end-start))        \n",
    "\n",
    "for k in distributions.keys():\n",
    "    fig = plt.figure(k,figsize=(30,30))\n",
    "    i = 0\n",
    "    for f in h0_sr[k]:\n",
    "        if classification[i] ==2:\n",
    "            color = \"black\"\n",
    "        else:\n",
    "            color = \"red\"\n",
    "        f.plot(color = color)\n",
    "        i += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('ml_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26105b2dc5f82e64c8b7ee8f072b1281e0bdab5f382708ceed93e75530eb79f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
